{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to use dataset for game called Connect 4. Linke for data:https://archive.ics.uci.edu/ml/datasets/Connect-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_data = pd.read_csv('connect-4.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our dataset we have 67556 samples and each has 42 features.\n"
     ]
    }
   ],
   "source": [
    "print(\"In our dataset we have {} samples and each has {} features.\".format(connect_data.shape[0], connect_data.shape[1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>b.1</th>\n",
       "      <th>b.2</th>\n",
       "      <th>b.3</th>\n",
       "      <th>b.4</th>\n",
       "      <th>b.5</th>\n",
       "      <th>b.6</th>\n",
       "      <th>b.7</th>\n",
       "      <th>b.8</th>\n",
       "      <th>b.9</th>\n",
       "      <th>...</th>\n",
       "      <th>b.25</th>\n",
       "      <th>b.26</th>\n",
       "      <th>b.27</th>\n",
       "      <th>b.28</th>\n",
       "      <th>b.29</th>\n",
       "      <th>b.30</th>\n",
       "      <th>b.31</th>\n",
       "      <th>b.32</th>\n",
       "      <th>b.33</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b b.1 b.2 b.3 b.4 b.5 b.6 b.7 b.8 b.9 ...  b.25 b.26 b.27 b.28 b.29 b.30  \\\n",
       "0  b   b   b   b   b   b   b   b   b   b ...     b    b    b    b    b    b   \n",
       "1  b   b   b   b   b   b   o   b   b   b ...     b    b    b    b    b    b   \n",
       "2  b   b   b   b   b   b   b   b   b   b ...     b    b    b    b    b    b   \n",
       "3  o   b   b   b   b   b   b   b   b   b ...     b    b    b    b    b    b   \n",
       "4  b   b   b   b   b   b   b   b   b   b ...     b    b    b    o    b    b   \n",
       "\n",
       "  b.31 b.32 b.33  win  \n",
       "0    b    b    b  win  \n",
       "1    b    b    b  win  \n",
       "2    b    b    b  win  \n",
       "3    b    b    b  win  \n",
       "4    b    b    b  win  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information: (x=player x has taken, o=player o has taken, b=blank) \n",
    "\n",
    "The board is numbered like: \n",
    "6 . . . . . . . \n",
    "5 . . . . . . . \n",
    "4 . . . . . . . \n",
    "3 . . . . . . . \n",
    "2 . . . . . . . \n",
    "1 . . . . . . . \n",
    "  a b c d e f g "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice all data is in string format, those next steps we should consider while working with this dataset:\n",
    "    0. Encode each layer to numbers\n",
    "    1. Split data into feauters and labels\n",
    "    2. win column (class column) also encode to 0 - 1 - 2 classes\n",
    "    3. Split data into training and testing set\n",
    "Note:\n",
    "    In this case, probably, we won't need to scale data, because when we encode the dataset, all columns are going to be in the same scale already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.0 and 1.2 Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method LabelEncoder should encode column by column, so first things first we will need to get list of all columns (just names of columns) from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['b', 'b.1', 'b.2', 'b.3', 'b.4', 'b.5', 'b.6', 'b.7', 'b.8', 'b.9',\n",
      "       'b.10', 'b.11', 'x', 'o', 'b.12', 'b.13', 'b.14', 'b.15', 'x.1', 'o.1',\n",
      "       'x.2', 'o.2', 'x.3', 'o.3', 'b.16', 'b.17', 'b.18', 'b.19', 'b.20',\n",
      "       'b.21', 'b.22', 'b.23', 'b.24', 'b.25', 'b.26', 'b.27', 'b.28', 'b.29',\n",
      "       'b.30', 'b.31', 'b.32', 'b.33', 'win'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns = connect_data.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "for column in columns:\n",
    "    connect_data[column] = encoder.fit_transform(connect_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>b.1</th>\n",
       "      <th>b.2</th>\n",
       "      <th>b.3</th>\n",
       "      <th>b.4</th>\n",
       "      <th>b.5</th>\n",
       "      <th>b.6</th>\n",
       "      <th>b.7</th>\n",
       "      <th>b.8</th>\n",
       "      <th>b.9</th>\n",
       "      <th>...</th>\n",
       "      <th>b.25</th>\n",
       "      <th>b.26</th>\n",
       "      <th>b.27</th>\n",
       "      <th>b.28</th>\n",
       "      <th>b.29</th>\n",
       "      <th>b.30</th>\n",
       "      <th>b.31</th>\n",
       "      <th>b.32</th>\n",
       "      <th>b.33</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  b.1  b.2  b.3  b.4  b.5  b.6  b.7  b.8  b.9 ...   b.25  b.26  b.27  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0 ...      0     0     0   \n",
       "1  0    0    0    0    0    0    1    0    0    0 ...      0     0     0   \n",
       "2  0    0    0    0    0    0    0    0    0    0 ...      0     0     0   \n",
       "3  1    0    0    0    0    0    0    0    0    0 ...      0     0     0   \n",
       "4  0    0    0    0    0    0    0    0    0    0 ...      0     0     0   \n",
       "\n",
       "   b.28  b.29  b.30  b.31  b.32  b.33  win  \n",
       "0     0     0     0     0     0     0    2  \n",
       "1     0     0     0     0     0     0    2  \n",
       "2     0     0     0     0     0     0    2  \n",
       "3     0     0     0     0     0     0    2  \n",
       "4     1     0     0     0     0     0    2  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.0 Splitting data into feautres and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = connect_data.iloc[:, :-1].values\n",
    "labels = connect_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [2 2 0 ..., 1 0 0]\n",
      " [2 1 0 ..., 2 2 0]\n",
      " [2 1 1 ..., 0 0 0]]\n",
      "[2 2 2 ..., 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have these classes in our dataset: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(labels)\n",
    "print(\"We have these classes in our dataset: {}\".format(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have these classes in our dataset: ['draw' 'loss' 'win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3 Split data into training and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (47289, 42)\n",
      "y_train shape: (47289,)\n",
      "X_test shape: (20267, 42)\n",
      "y_test shape: (20267,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Choose best features - Feature Enigineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most cases we don't have to do feature engineering becuase all feauteres might be usefull but in this case we have 42 features which is pretty much. To reduce this number\n",
    "to some smaller number we are going to do Feature engineering part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=400, random_state=0)\n",
    "etc.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance_of_feautres = etc.feature_importances_\n",
    "indices = np.argsort(importance_of_feautres)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05913364  0.03662601  0.02356622  0.0129138   0.00627607  0.0025215\n",
      "  0.05667404  0.04503789  0.02943263  0.01540736  0.00651408  0.00257254\n",
      "  0.05410683  0.05851629  0.04335059  0.01771883  0.00691437  0.00272518\n",
      "  0.06265455  0.0485316   0.03929703  0.01449202  0.00451069  0.00138346\n",
      "  0.05386647  0.02917772  0.015893    0.00669322  0.00222387  0.00049316\n",
      "  0.05720242  0.03174286  0.01788838  0.00795296  0.0026991   0.00061286\n",
      "  0.05567298  0.03348548  0.02021993  0.00910043  0.00340306  0.00079485]\n"
     ]
    }
   ],
   "source": [
    "print(importance_of_feautres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAJOCAYAAAByawKQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2098a63b860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(features.shape[1]), importance_of_feautres[indices], color=\"b\", align=\"center\")\n",
    "plt.xticks(range(features.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top 5 feautres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.1\n",
      "b\n",
      "o\n",
      "b.22\n",
      "b.6\n"
     ]
    }
   ],
   "source": [
    "features = connect_data.columns\n",
    "for i in range(5):\n",
    "    print(features[indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Prediction using Tree classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifer: 73.10406078847387%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Random Forest Classifer: {}%\".format(accuracy_score(y_test, dtc.predict(X_test))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = P = True_positive / (True_positive + False_positive):  0.72378925425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls = True_positive / (True_positive + False_negative):  0.717587609078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "precisions = cross_val_score(dtc, X_train, y_train, cv=10, scoring='precision')\n",
    "print('Precision = P = True_positive / (True_positive + False_positive): ', np.mean(precisions))\n",
    "\n",
    "recalls = cross_val_score(dtc, X_train, y_train, cv=5, scoring='recall')\n",
    "print('Recalls = True_positive / (True_positive + False_negative): ', np.mean(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 Prediction using Ensemble classifers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifer: 81.44767355800069%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Random Forest Classifer: {}%\".format(accuracy_score(y_test, rfc.predict(X_test))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R',n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Ada Boost Classifer: 73.39024029210046%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Ada Boost Classifer: {}%\".format(accuracy_score(y_test, ada.predict(X_test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2.1 Grid Search for the best set of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {'criterion':['gini', 'entropy'], 'n_estimators':[10, 100, 300, 350, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grind search for Random forest classifier took:  899.8626782894135\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gsCV = GridSearchCV(rfc, param_grid=params_grid, cv=10)\n",
    "gsCV.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Grind search for Random forest classifier took: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(gsCV.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2.2 Fine tune params in Random Forest Classifier according to Grind Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifer: 81.6943800266443%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Random Forest Classifer: {}%\".format(accuracy_score(y_test, rfc.predict(X_test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning those params did improve test accuracy but it was almost unnoticeable. So we go further..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Further tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN: 74.1451620861499%\n",
      "Time for knn:  24.455848932266235\n"
     ]
    }
   ],
   "source": [
    "start_knn = time.time()\n",
    "print(\"Accuracy for KNN: {}%\".format(accuracy_score(y_test, knn.predict(X_test))*100))\n",
    "end_knn = time.time()\n",
    "time_knn = end_knn - start_knn\n",
    "print(\"Time for knn: \", time_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liner_classifer = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Linear Classifer: 66.3295011595204%\n",
      "Time for Linear Classifier:  0.005014181137084961\n"
     ]
    }
   ],
   "source": [
    "liner_classifer.fit(X_train, y_train)\n",
    "start_linea = time.time()\n",
    "print(\"Accuracy for Linear Classifer: {}%\".format(accuracy_score(y_test, liner_classifer.predict(X_test))*100))\n",
    "end_linea = time.time()\n",
    "time_linea = end_linea - start_linea\n",
    "print(\"Time for Linear Classifier: \", time_linea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to all tests that we have performed, Ensembled models showed the best performance on the test set. In the first place was Random Forest Classifier with 81.7%.\n",
    "With the Fine tunning we got about 0.5% more than with starting setup of this algorithm. \n",
    "\n",
    "Note for simple methods: Linear Classifier (Logistic Regression) is running very fast but accuracy is about 10% lower than KNN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
